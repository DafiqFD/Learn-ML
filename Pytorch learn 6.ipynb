{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOy/Fq5F9LfgdHxSiJHk+2m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 1. Get data\n","\n"],"metadata":{"id":"xnYYIFvVsw_9"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"u0By01mgSQME","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753151402270,"user_tz":-420,"elapsed":475,"user":{"displayName":"dafiq","userId":"15316246597210458884"}},"outputId":"26f663c6-3f6a-4514-dd59-1faa26b924ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["data/pizza_steak_sushi already exist\n","Downloading data\n","Unzipping pizza, steak, sushi data...\n"]}],"source":["from typing_extensions import dataclass_transform\n","import os\n","import requests\n","import zipfile\n","from pathlib import Path\n","from torchvision import datasets, transforms\n","\n","# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"pizza_steak_sushi\"\n","\n","# If the image folder doesnt exist download\n","if image_path.is_dir():\n","  print(f\"{image_path} already exist\")\n","else:\n","  print(f\"Not available yet. creating one\")\n","  image_path.mkdir(parents=True, exist_ok=True)\n","\n","# Download dataset\n","with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","  print(\"Downloading data\")\n","  f.write(request.content)\n","\n","# Unzip pizza, steak, sushi data\n","with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","    print(\"Unzipping pizza, steak, sushi data...\")\n","    zip_ref.extractall(image_path)\n","\n","# Remove zip file\n","os.remove(data_path / \"pizza_steak_sushi.zip\")\n","\n","# create simple transfomr\n","data_transform = transforms.Compose([\n","    transforms.Resize((64,64)),\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"markdown","source":["## 2. Datasets and Dataloader with script"],"metadata":{"id":"JFOMII74001x"}},{"cell_type":"code","source":["# Create a directory for going_modular scripts\n","import os\n","os.makedirs(\"going_modular\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"iZXOQaVE-3vd","executionInfo":{"status":"error","timestamp":1753151452816,"user_tz":-420,"elapsed":30,"user":{"displayName":"dafiq","userId":"15316246597210458884"}},"outputId":"06dc751d-0dff-4607-b2cf-9f682386e72b"},"execution_count":16,"outputs":[{"output_type":"error","ename":"FileExistsError","evalue":"[Errno 17] File exists: 'going_modular'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-16-2488296081.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a directory for going_modular scripts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"going_modular\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'going_modular'"]}]},{"cell_type":"code","source":["%%writefile going_modular/data_setup.py\n","\n","\"\"\" Contains functionality for creating PyTorch DataLoader for image classification data \"\"\"\n","import os\n","\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","NUM_WORKERS = os.cpu_count()\n","\n","def create_dataloaders(\n","    train_dir: str,\n","    test_dir: str,\n","    transform: transforms.Compose,\n","    batch_size: int,\n","    numworkers: int=NUM_WORKERS\n","):\n","  \"\"\" Creates training and testing DataLoaders\n","  Takes in a training directory and testing directory path and turns\n","  them into PyTorch Datasets and then into PyTorch DataLoaders.\n","\n","  Args:\n","    train_dir: Path to training directory.\n","    test_dir: Path to testing directory.\n","    transform: torchvision transforms to perform on training and testing data.\n","    batch_size: Number of samples per batch in each of the DataLoaders.\n","    num_workers: An integer for number of workers per DataLoader.\n","\n","  Returns:\n","    A tuple of (train_dataloader, test_dataloader, class_names).\n","    Where class_names is a list of the target classes.\n","    Example usage:\n","      train_dataloader, test_dataloader, class_names = \\\n","        = create_dataloaders(train_dir=path/to/train_dir,\n","                             test_dir=path/to/test_dir,\n","                             transform=some_transform,\n","                             batch_size=32,\n","                             num_workers=4)\n","  \"\"\"\n","\n","  # Use imagefolder to create dataset\n","  train_data = datasets.ImageFolder(train_dir, transform = transform)\n","  test_data = datasets.ImageFolder(test_dir, transform = transform)\n","\n","  train_dir = image_path / \"train\"\n","  test_dir = image_path / \"test\"\n","\n","  # Get class names\n","  class_names = train_data.classes\n","\n","  # Turn images into data loaders\n","  train_dataloader = DataLoader(\n","      train_data,\n","      batch_size = batch_size,\n","      shuffle = True,\n","      num_workers = NUM_WORKERS,\n","      pin_memory= True\n","  )\n","  test_dataloader = DataLoader (\n","      test_data,\n","      batch_size=batch_size,\n","      shuffle=False,\n","      num_workers=NUM_WORKERS,\n","      pin_memory=True\n","  )\n","\n","  return train_dataloader, test_dataloader, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_EUNFH-IzxSQ","executionInfo":{"status":"ok","timestamp":1753151410137,"user_tz":-420,"elapsed":10,"user":{"displayName":"dafiq","userId":"15316246597210458884"}},"outputId":"902b6836-a206-43bd-f966-1b723a5afa01"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/data_setup.py\n"]}]},{"cell_type":"code","source":["# Test out the data_setup.py\n","# Import data_setup.py\n","from going_modular import data_setup\n","\n","# Create train/test dataloader and get class names as a list\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir = train_dir,\n","                                                                               test_dir = test_dir,\n","                                                                               transforms = data_transform,\n","                                                                               batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"RNR6Ie4R-w0b","executionInfo":{"status":"error","timestamp":1753151410646,"user_tz":-420,"elapsed":36,"user":{"displayName":"dafiq","userId":"15316246597210458884"}},"outputId":"fd0d28d8-4f95-4ba5-8c62-87a801d4cf3b"},"execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'train_dir' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-15-4255883969.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create train/test dataloader and get class names as a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir = train_dir,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                                                                \u001b[0mtest_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                                                \u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_dir' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"G39pgXZE8Gi5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# I think its just adding docstring to our previous learn and use the %%writefile on top of it - https://www.learnpytorch.io/05_pytorch_going_modular/"],"metadata":{"id":"OmIpNFOXIzhO"}},{"cell_type":"code","source":[],"metadata":{"id":"63Lb2139I-q_"},"execution_count":null,"outputs":[]}]}